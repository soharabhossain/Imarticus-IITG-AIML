{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Semantic Indexing/Analysis (LSI/LSA)"
      ],
      "metadata": {
        "id": "TWME2z7QjVma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the Libraries"
      ],
      "metadata": {
        "id": "VGN4DgsHlM0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qs4xFg6UjS6N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loda Data"
      ],
      "metadata": {
        "id": "YionomoWnWGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kSQkjgjnVid",
        "outputId": "60edfcd2-7ad8-444d-e91b-6079ba0f1793"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents_list = []\n",
        "\n",
        "with open(os.path.join(\"articles.txt\"), \"r\") as fin:\n",
        "  for line in fin.readlines():\n",
        "    text = line.strip()\n",
        "    documents_list.append(text)\n"
      ],
      "metadata": {
        "id": "H4T7xQA4njEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents_list"
      ],
      "metadata": {
        "id": "WKZtQr-RpTcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and Extraction of TF-IDF Features"
      ],
      "metadata": {
        "id": "3Au8s6Q-p7SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tonekizer = RegexpTokenizer(r'\\w+')"
      ],
      "metadata": {
        "id": "NEa8IlTQp19q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize the documents using TF-IDF"
      ],
      "metadata": {
        "id": "B1dUpy2sqcOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf  = TfidfVectorizer(lowercase=True, stop_words='english', \n",
        "                         ngram_range=(1,1), tokenizer= tonekizer.tokenize)\n",
        "\n",
        "train_data =  tfidf.fit_transform(documents_list)"
      ],
      "metadata": {
        "id": "Azk4P-RXqbGh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Topic Modeling"
      ],
      "metadata": {
        "id": "Ar_OSQg6r8pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of topics\n",
        "num_components = 10\n",
        "\n",
        "# Create a SVD object\n",
        "lsa = TruncatedSVD(n_components = num_components,\n",
        "                   n_iter=100,\n",
        "                   random_state=42)\n",
        "\n",
        "# Train the model\n",
        "lsa.fit_transform(train_data)\n"
      ],
      "metadata": {
        "id": "EWekAHT6sAlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract topics and terms"
      ],
      "metadata": {
        "id": "tI5aC4iTsmPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the topics with their terms\n",
        "\n",
        "terms = tfidf.get_feature_names_out()\n",
        "\n",
        "for index, component in enumerate(lsa.components_):\n",
        "  zipperd = zip(terms, component)\n",
        "  top_terms_key = sorted(zipped, key = lambda t: t[1], reverse=True)[:5]\n",
        "  top_terms_list = list(dict(top_terms_key).keys())\n",
        "  print(\"Topic \" + str(index) + \":\", top_terms_list)\n"
      ],
      "metadata": {
        "id": "RPXUKxdAssNI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}